{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Emotion-Based Game Recommendation System on Steam"]},{"cell_type":"markdown","metadata":{},"source":["This model recommends steam games based on the user's emotions.\n","<br>The base model is Google's Gemma-2b-it, (https://www.kaggle.com/models/google/gemma/Transformers/2b-it/3)\n","<br>and the dataset is sourced from https://www.kaggle.com/datasets/antonkozyriev/game-recommendations-on-steam.\n","<br>For more details, the reference notebook can be found here.\n","(https://www.datacamp.com/tutorial/fine-tuning-gemma-2)\n","<br>finally, If you want to use the fine-tuned model, you can use it by modifying the \"\"question variable\"\" in this notebook.\n","<br>and accelerator was run on GPU P100. (https://www.kaggle.com/code/dpwls0213/using-the-fine-tuning-model/notebook)"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-29T00:48:51.343743Z","iopub.status.busy":"2024-09-29T00:48:51.343336Z","iopub.status.idle":"2024-09-29T00:50:20.988574Z","shell.execute_reply":"2024-09-29T00:50:20.987197Z","shell.execute_reply.started":"2024-09-29T00:48:51.343698Z"},"trusted":true},"outputs":[],"source":["%%capture\n","%pip install -U transformers \n","%pip install -U datasets \n","%pip install -U accelerate \n","%pip install -U peft \n","%pip install -U trl \n","%pip install -U bitsandbytes"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:50:23.821601Z","iopub.status.busy":"2024-09-29T00:50:23.821178Z","iopub.status.idle":"2024-09-29T00:50:44.814263Z","shell.execute_reply":"2024-09-29T00:50:44.813466Z","shell.execute_reply.started":"2024-09-29T00:50:23.821560Z"},"trusted":true},"outputs":[],"source":["from transformers import (\n","    AutoModelForCausalLM,\n","    AutoTokenizer,\n","    BitsAndBytesConfig,\n","    HfArgumentParser,\n","    TrainingArguments,\n","    pipeline,\n","    logging,\n",")\n","from peft import (\n","    LoraConfig,\n","    PeftModel,\n","    prepare_model_for_kbit_training,\n","    get_peft_model,\n",")\n","import os, torch\n","from datasets import load_dataset\n","from trl import SFTTrainer, setup_chat_format"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:51:35.773703Z","iopub.status.busy":"2024-09-29T00:51:35.772930Z","iopub.status.idle":"2024-09-29T00:51:35.778340Z","shell.execute_reply":"2024-09-29T00:51:35.777313Z","shell.execute_reply.started":"2024-09-29T00:51:35.773660Z"},"trusted":true},"outputs":[],"source":["base_model = \"/kaggle/input/gemma/transformers/2b-it/3\"\n","dataset_name = \"/kaggle/input/game-recommendation-steam\"\n","new_model = \"Gemma-2b-it-game-recommendation\""]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:51:37.497183Z","iopub.status.busy":"2024-09-29T00:51:37.496808Z","iopub.status.idle":"2024-09-29T00:51:37.566274Z","shell.execute_reply":"2024-09-29T00:51:37.565291Z","shell.execute_reply.started":"2024-09-29T00:51:37.497149Z"},"trusted":true},"outputs":[],"source":["if torch.cuda.get_device_capability()[0] >= 8:\n","    !pip install -qqq flash-attn\n","    torch_dtype = torch.bfloat16\n","    attn_implementation = \"flash_attention_2\"\n","else:\n","    torch_dtype = torch.float16\n","    attn_implementation = \"eager\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:51:39.104869Z","iopub.status.busy":"2024-09-29T00:51:39.104477Z","iopub.status.idle":"2024-09-29T00:51:39.111602Z","shell.execute_reply":"2024-09-29T00:51:39.110494Z","shell.execute_reply.started":"2024-09-29T00:51:39.104833Z"},"trusted":true},"outputs":[],"source":["# QLoRA config\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch_dtype,\n","    bnb_4bit_use_double_quant=True,\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:51:40.890878Z","iopub.status.busy":"2024-09-29T00:51:40.889936Z","iopub.status.idle":"2024-09-29T00:52:06.514548Z","shell.execute_reply":"2024-09-29T00:52:06.513735Z","shell.execute_reply.started":"2024-09-29T00:51:40.890817Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["`config.hidden_act` is ignored, you should use `config.hidden_activation` instead.\n","Gemma's activation function will be set to `gelu_pytorch_tanh`. Please, use\n","`config.hidden_activation` if you want to override this behaviour.\n","See https://github.com/huggingface/transformers/pull/29402 for more details.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"019127dc91a14155b1f333f9e3adc8e7","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load model\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\",\n","    attn_implementation=attn_implementation\n",")\n","\n","# Load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:52:22.231181Z","iopub.status.busy":"2024-09-29T00:52:22.230305Z","iopub.status.idle":"2024-09-29T00:52:22.238244Z","shell.execute_reply":"2024-09-29T00:52:22.237228Z","shell.execute_reply.started":"2024-09-29T00:52:22.231141Z"},"trusted":true},"outputs":[],"source":["import bitsandbytes as bnb\n","\n","def find_all_linear_names(model):\n","    cls = bnb.nn.Linear4bit\n","    lora_module_names = set()\n","    for name, module in model.named_modules():\n","        if isinstance(module, cls):\n","            names = name.split('.')\n","            lora_module_names.add(names[0] if len(names) == 1 else names[-1])\n","    if 'lm_head' in lora_module_names:\n","        lora_module_names.remove('lm_head')\n","    return list(lora_module_names)\n","\n","modules = find_all_linear_names(model)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:52:29.366954Z","iopub.status.busy":"2024-09-29T00:52:29.366584Z","iopub.status.idle":"2024-09-29T00:52:29.885159Z","shell.execute_reply":"2024-09-29T00:52:29.884088Z","shell.execute_reply.started":"2024-09-29T00:52:29.366921Z"},"trusted":true},"outputs":[],"source":["# LoRA config\n","peft_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n","    target_modules=modules\n",")\n","model, tokenizer = setup_chat_format(model, tokenizer)\n","model = get_peft_model(model, peft_config)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:52:32.486902Z","iopub.status.busy":"2024-09-29T00:52:32.485841Z","iopub.status.idle":"2024-09-29T00:52:33.901107Z","shell.execute_reply":"2024-09-29T00:52:33.899899Z","shell.execute_reply.started":"2024-09-29T00:52:32.486860Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21ae1c7855394d97b889527fdd4baaf0","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2962b0b7341143d68f0f9ec46c26c0ed","version_major":2,"version_minor":0},"text/plain":["Map (num_proc=4):   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/multiprocess/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n"]},{"data":{"text/plain":["Dataset({\n","    features: ['instruction', 'input', 'output', 'text'],\n","    num_rows: 1000\n","})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["dataset = load_dataset(dataset_name, split=\"all\")\n","dataset = dataset.shuffle(seed=65).select(range(1000))\n","\n","def format_chat_template(row):\n","    row_json = [{\"role\": \"system\", \"content\": row[\"instruction\"]},\n","               {\"role\": \"user\", \"content\": row[\"input\"]},\n","               {\"role\": \"assistant\", \"content\": row[\"output\"]}]\n","    row[\"text\"] = tokenizer.apply_chat_template(row_json, tokenize=False)\n","    return row\n","\n","dataset = dataset.map(\n","    format_chat_template,\n","    num_proc= 4,\n",")\n","\n","dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:52:36.946227Z","iopub.status.busy":"2024-09-29T00:52:36.945807Z","iopub.status.idle":"2024-09-29T00:52:36.964801Z","shell.execute_reply":"2024-09-29T00:52:36.963634Z","shell.execute_reply.started":"2024-09-29T00:52:36.946186Z"},"trusted":true},"outputs":[],"source":["dataset = dataset.train_test_split(test_size=0.1)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T00:52:44.190029Z","iopub.status.busy":"2024-09-29T00:52:44.188915Z","iopub.status.idle":"2024-09-29T01:00:57.186892Z","shell.execute_reply":"2024-09-29T01:00:57.185923Z","shell.execute_reply.started":"2024-09-29T00:52:44.189982Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length, dataset_text_field. Will not be supported from version '1.0.0'.\n","\n","Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n","  warnings.warn(message, FutureWarning)\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:321: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac962a3c508f43e88d73ba35e637085f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/900 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7d505e18e204e04b707901f0e2d5e91","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/100 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [450/450 08:08, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>90</td>\n","      <td>No log</td>\n","      <td>1.329416</td>\n","    </tr>\n","    <tr>\n","      <td>180</td>\n","      <td>No log</td>\n","      <td>1.297145</td>\n","    </tr>\n","    <tr>\n","      <td>270</td>\n","      <td>No log</td>\n","      <td>1.290923</td>\n","    </tr>\n","    <tr>\n","      <td>360</td>\n","      <td>No log</td>\n","      <td>1.269847</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>No log</td>\n","      <td>1.255013</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n","  warnings.warn(\n"]},{"data":{"text/plain":["TrainOutput(global_step=450, training_loss=1.4963372124565972, metrics={'train_runtime': 489.9528, 'train_samples_per_second': 1.837, 'train_steps_per_second': 0.918, 'total_flos': 1519219575410688.0, 'train_loss': 1.4963372124565972, 'epoch': 1.0})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["# Setting Hyperparamter \n","training_arguments = TrainingArguments(\n","    output_dir=new_model,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=2,\n","    optim=\"paged_adamw_32bit\",\n","    num_train_epochs=1,\n","    eval_strategy=\"steps\",\n","    eval_steps=0.2,\n","    logging_steps=1,\n","    logging_strategy=\"no\",\n","    warmup_steps=10,\n","    learning_rate=2e-4,\n","    fp16=False,\n","    bf16=False,\n","    group_by_length=True,\n","    report_to=\"none\",\n",")\n","\n","# Setting sft parameters\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset[\"train\"],\n","    eval_dataset=dataset[\"test\"],\n","    peft_config=peft_config,\n","    max_seq_length= 512,\n","    dataset_text_field=\"text\",\n","    tokenizer=tokenizer,\n","    args=training_arguments,\n","    packing= False,\n",")\n","\n","model.config.use_cache = False\n","trainer.train()"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T01:03:36.414196Z","iopub.status.busy":"2024-09-29T01:03:36.413228Z","iopub.status.idle":"2024-09-29T01:03:36.418323Z","shell.execute_reply":"2024-09-29T01:03:36.417280Z","shell.execute_reply.started":"2024-09-29T01:03:36.414152Z"},"trusted":true},"outputs":[],"source":["base_model_url = \"/kaggle/input/gemma/transformers/2b-it/3\"\n","new_model_url = \"dpwls003/Gemma-2b-it-game-recommendation\""]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T01:03:44.877282Z","iopub.status.busy":"2024-09-29T01:03:44.876246Z","iopub.status.idle":"2024-09-29T01:03:50.777137Z","shell.execute_reply":"2024-09-29T01:03:50.776323Z","shell.execute_reply.started":"2024-09-29T01:03:44.877241Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d00cf809fa494d57927023dad3115879","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Reload tokenizer and model\n","tokenizer = AutoTokenizer.from_pretrained(base_model_url)\n","\n","base_model_reload= AutoModelForCausalLM.from_pretrained(\n","    base_model_url,\n","    low_cpu_mem_usage=True,\n","    return_dict=True,\n","    torch_dtype=torch.float16,\n","    device_map=\"cpu\",\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-09-29T01:04:06.539446Z","iopub.status.busy":"2024-09-29T01:04:06.538548Z","iopub.status.idle":"2024-09-29T01:05:18.242820Z","shell.execute_reply":"2024-09-29T01:05:18.241916Z","shell.execute_reply.started":"2024-09-29T01:04:06.539384Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"56f751f5070c41868a0597b621cee98b","version_major":2,"version_minor":0},"text/plain":["adapter_config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7c6cb4f3fd04947b2a981a3326df47c","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/2.18G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["base_model_reload, tokenizer = setup_chat_format(base_model_reload, tokenizer)\n","\n","model = PeftModel.from_pretrained(base_model_reload, new_model_url)\n","\n","model = model.merge_and_unload()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.save_pretrained(\"Gemma-2b-it-game-recommendation\")\n","tokenizer.save_pretrained(\"Gemma-2b-it-game-recommendation\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model.push_to_hub(\"Gemma-2b-it-game-recommendation\", use_temp_dir=False)\n","tokenizer.push_to_hub(\"Gemma-2b-it-game-recommendation\", use_temp_dir=False)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5781220,"sourceId":9499796,"sourceType":"datasetVersion"},{"isSourceIdPinned":true,"modelId":3301,"modelInstanceId":8318,"sourceId":28785,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30776,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
